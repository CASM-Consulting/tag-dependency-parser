==================================================================================================
This is the dependency parser guide. Where appropriate, it will defer to the comments in the 
source code of particular classes. Its purpose is to provide a general guide for the use and 
development of the  parser project.
==================================================================================================

Contents:

  1. Overall structure
  2. Input
  3. Output
  4. Training
  5. Extension of functionality

-- 1. Overall structure --

This project implements transition-based dependency parsing. A transition-based parser acts as
a finite state machine, which consumes tokens from an input sentence and changes state via
transitions, the side effects of some of which are to produce dependency relations with the aim
of assigning a full dependency tree to the input sentence.

The top-level class is the Parser class. This class contains methods for training and prediction
using the parser.

This functionality can be broken down in to discrete modules of functionality (mirrored by 
project package structure):

  Parser states:
    Parser states define what data structures the parser states are composed of. They are 
    responsible for initialisation of the state for a new sentence, for determining if the state is 
    terminal, and for defining how the feature extraction process should index into the state's 
    datastructures. See the ParserState interface in the parserstates package.

    BEAM SEARCH: currently beam search is not implemented. However, its possibility has been
                 kept in mind during development. All parser states have a method "copy()",
                 which will make a complete clone of the current parser state (which will be
                 required for doing any kind of search of possible parses). See the copy method
                 comments in the ParserState abstract class for details.

  Parse styles: 
    Parser styles determine what transitions are available to the parser. And therefore they also 
    specify a particular parser state that they require. They are responsible for providing new 
    parser states of the appropriate type, for checking feasibility of and performing transitions, 
    and also during training, for using the gold standard to select the appropriate transition. See 
    the ParseStyle class in the parsestyles package.

  Classifiers:
    At each step of parsing, the best transition to make must be inferred. A classifier that 
    is able to select the best transition given a vector representation of the parser state is 
    used for this process. The classifier's responsibility is to be able to be trained from
    many of such vectors (paired with the appropriate transitions) and given a new vector, 
    make a prediction.  It is also responsible for loading pre-trained classifier models. See
    Classifier interface in classifiers package.

  Transition Selection methods: 
    It is the duty of selection methods to take the classifier's output, and perform an 
    appropriate transition. See SelectionMethod interface in the transitionselectionmethods
    package.

  Feature extraction:
    Feature selection is a rich and configurable aspect of training and prediction. A full
    specification of all features to be extracted whenever the parser produces a feature
    vector of its state is referred to as a "feature table". A default feature table is
    provided, but the user may provide their own. Generally, any feature of a token
    can be used that the user specified when defining the input format of sentences. 
    So, if the user said that tokens have "PoS" and "Morphology" feature types, then these
    feature types will be available for extraction, and can be specified in the feature 
    table. Addressing functions are used to reference particular tokens in the parser's 
    state. See the FeatureTable class in the top-level package.

  Feature indexing:
    In order to make numeric features (and transitions), every feature, which is fully 
    specified with type and value as a String, is assigned an integer ID. This mapping is 
    maintained by the Index class in the top-level package. Together with the classifier
    model and the feature table, these three make up the required data which the parser
    needs in order to parse things.

-- 2. Input --

This section discusses input methods at parse-time. See the separate section on training 
for a guide on inputs for training.

Parsing functionality is located in the Parser class in the top-level package.

Fundamentally, the parser expects a list of Token objects (see Token in datastructures package)
to which it then assigns each a head token, and a dependency relation type. See section on 
outputs for how to deal with this).

Each token is basically a map of feature types to feature values (e.g. PoS --> Noun). Each 
token has a within-sentence ID (starting from 1, and the artificial root is 0).

It is possible to create this list yourself, but you'd have to ensure that each token was
initialised with the correct ID, and pass in all the token attributes yourself.

A better solution in most cases is to use the Sentence class in the datastructures package.
A Sentence object is essentially a list of Tokens (so can be passed directly to the parse
methods), whose instantiation is mostly handled for you if you do it right.

Essentially, you ensure that whatever data type you're using to hold your tokens implements
one of the interfaces defined in the Sentence class, then pass a bunch of them to one of the
static create methods. It'll then do all the proper initialisation for you.

Alternatively, you can create an empty Sentence using the constructor, then make successive
calls to the add() methods with the appropriate data, and again the Token objects'll be
created for you. Then pass the Sentence straight to the parse methods.

-- 3. Output --

The parser directly modifies the Tokens you pass to it, by annotating each Token with a 
reference to the Token which is its head, and also what type the dependency relation
is. See the Token class in the datastructures package.

You can access the relation type by calling "getDeprel()" on a Token object.

You can access the head Token by calling "getHead()" on a Token object.

Alternatively you can call "getHeadID()" if you just want the ID of the head Token.

Functionality is being rolled in that enables the parser to directly annotate your
objects with dependency relations, using the ParsableWithAttributeMap and
ParsableWithPoSandForm interfaces. Rather than returning these Token objects that
you then query for head and deprel. We still need to maintain the Token objects
internally though, because they carry other data. So this is purely a cosmetic gain.

-- 4. Training --

Training methods are located in the Parser class in the top-level package.

A file containing sentence pre-annotated with dependencies is expected.

See the CoNLLReader class in the top-level package for the data format expected. A 
CoNLLReader requires a "data format string", which you can pass to it through the training 
methods. This allows you to specify what features each Token is associated with.

The training methods explain other inputs necessary. The different training methods are
there simply to give sensible defaults where desired.

This could consume A LOT of RAM. The default feature table leads to a model that may well eat
up 8 - 11 GB during training (blame support vector machines and massive feature models)
Once that's done though, to use the actual training parser requires around 1-2GB, probably less.

-- 5. Extension of functionality --

The parser is designed to be easily extendable in several areas. In fact, you can add classifiers,
parser states, parse styles, and transition selection methods all without having to change the 
source code and recompile. Simply create a project with this one as a dependency, and add classes
to the relevant package hierarchy. See the Options class in the top-level package. MAGIC.

==================================================================================================
IF YOU DID NOT INTEND TO SEE THIS HELP FILE, YOU WERE PROBABLY TRYING TO DO A SIMPLE TRAINING
OR PARSING RUN ON A SINGLE FILE BY RUNNING THE MAIN METHOD OF THE PARSER CLASS, OR DIDN'T REALISE
THAT THE PARSER HAS A DEFAULT BEHAVIOUR IN THE MAIN METHOD. YOU DONE GOOFED. GO CHECK THE MAIN
METHOD AT THE BOTTOM OF THE PARSER CLASS.
==================================================================================================
